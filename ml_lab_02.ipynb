{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOpUbhoVHQJ9R1bkMLiOol5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shreyacy/ML-LABB/blob/main/ml_lab_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "file_path = \"/content/WEATHER.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "print(\"Dataset Loaded Successfully:\\n\")\n",
        "print(df.head())\n",
        "def entropy(data):\n",
        "    \"\"\"Calculate entropy of the target column.\"\"\"\n",
        "    labels = data.iloc[:, -1]\n",
        "    label_counts = Counter(labels)\n",
        "    total_instances = len(data)\n",
        "\n",
        "    entropy_value = -sum((count / total_instances) * np.log2(count / total_instances) for count in label_counts.values())\n",
        "    return entropy_value\n",
        "dataset_entropy = entropy(df)\n",
        "print(f\"\\nEntropy of the dataset: {dataset_entropy:.4f}\")\n",
        "\n",
        "def entropy_of_attribute(data, attribute):\n",
        "    \"\"\"Calculate entropy for an attribute based on the target column.\"\"\"\n",
        "    attribute_values = data[attribute].unique()\n",
        "    entropy_values = {}\n",
        "\n",
        "    for value in attribute_values:\n",
        "        subset = data[data[attribute] == value]\n",
        "        entropy_values[value] = entropy(subset)\n",
        "\n",
        "    return entropy_values\n",
        "\n",
        "\n",
        "ignore_columns = [\"Day\"]  # Ignore specific columns if needed\n",
        "attribute_entropies = {}\n",
        "\n",
        "for attr in df.columns[:-1]:  # Exclude target column\n",
        "    if attr in ignore_columns:\n",
        "        continue\n",
        "\n",
        "    attribute_entropies[attr] = entropy_of_attribute(df, attr)\n",
        "    print(f\"\\nAttribute: {attr}\")\n",
        "    for val, ent in attribute_entropies[attr].items():\n",
        "        print(f\" - {val}: {ent:.4f}\")\n",
        "\n",
        "# Step 6: Function to calculate information gain\n",
        "def information_gain(data, attribute):\n",
        "    \"\"\"Calculate information gain for a given attribute.\"\"\"\n",
        "    total_entropy = entropy(data)\n",
        "\n",
        "    attribute_values = data[attribute].unique()\n",
        "    total_instances = len(data)\n",
        "\n",
        "    weighted_entropy = 0\n",
        "    for value in attribute_values:\n",
        "        subset = data[data[attribute] == value]\n",
        "        prob = len(subset) / total_instances\n",
        "        weighted_entropy += prob * entropy(subset)\n",
        "\n",
        "    gain = total_entropy - weighted_entropy\n",
        "    return gain\n",
        "\n",
        "# Step 7: Compute information gain for each attribute\n",
        "attributes = df.columns[:-1]  # Exclude target column\n",
        "gains = {attr: information_gain(df, attr) for attr in attributes if attr not in ignore_columns}\n",
        "\n",
        "print(\"\\nInformation Gain for Each Attribute:\")\n",
        "for attr, gain in gains.items():\n",
        "    print(f\"{attr}: {gain:.4f}\")\n",
        "\n",
        "# Step 8: Function to build the ID3 decision tree\n",
        "def id3(data, features, target):\n",
        "    \"\"\"Recursively builds a decision tree using ID3.\"\"\"\n",
        "    # If all target values are the same, return the value (pure leaf node)\n",
        "    if len(np.unique(data[target])) == 1:\n",
        "        return np.unique(data[target])[0]\n",
        "\n",
        "    # If no features left, return the most common target value\n",
        "    if len(features) == 0:\n",
        "        return data[target].mode()[0]\n",
        "\n",
        "    # Select the best feature using information gain\n",
        "    best_feature = max(features, key=lambda attr: information_gain(data, attr))\n",
        "    tree = {best_feature: {}}\n",
        "\n",
        "    # Create a subtree for each unique value of the best feature\n",
        "    for value in np.unique(data[best_feature]):\n",
        "        subset = data[data[best_feature] == value]\n",
        "        subtree = id3(subset, [f for f in features if f != best_feature], target)\n",
        "        tree[best_feature][value] = subtree\n",
        "\n",
        "    return tree\n",
        "\n",
        "# Step 9: Train the ID3 decision tree\n",
        "features = list(df.columns[:-1])  # Exclude target column\n",
        "target = df.columns[-1]  # Target column\n",
        "decision_tree = id3(df, features, target)\n",
        "\n",
        "# Step 10: Print the Decision Tree in a structured way\n",
        "def print_tree(tree, depth=0):\n",
        "    \"\"\"Recursively prints the decision tree row-wise with proper indentation.\"\"\"\n",
        "    if not isinstance(tree, dict):\n",
        "        print(\"  \" * depth + f\"⮕ Decision: {tree}\")\n",
        "        return\n",
        "\n",
        "    for attribute, branches in tree.items():\n",
        "        print(\"  \" * depth + f\"[{attribute}]\")\n",
        "        for value, subtree in branches.items():\n",
        "            print(\"  \" * (depth + 1) + f\"→ {value}:\")\n",
        "            print_tree(subtree, depth + 2)\n",
        "\n",
        "print(\"\\n=== Decision Tree (Row-wise) ===\")\n",
        "print_tree(decision_tree)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64yT1U3PInrs",
        "outputId": "a19a2895-b360-4e83-d06e-63d757fcfd67"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Loaded Successfully:\n",
            "\n",
            "   DAY   OUTLOOK TEMPERTATURE HUMIDITY    WIND DECISION\n",
            "0    1     SUNNY          HOT     HIGH    WEAK       NO\n",
            "1    2     SUNNY         HOIT     HIGH  STRONG       NO\n",
            "2    3  OVERCAST          HOT     HIGH    WEAK      YES\n",
            "3    4      RAIN         MILD     HIGH    WEAK      YES\n",
            "4    5      RAIN         COOL   NORMAL    WEAK      YES\n",
            "\n",
            "Entropy of the dataset: 0.9403\n",
            "\n",
            "Attribute: DAY\n",
            " - 1: -0.0000\n",
            " - 2: -0.0000\n",
            " - 3: -0.0000\n",
            " - 4: -0.0000\n",
            " - 5: -0.0000\n",
            " - 6: -0.0000\n",
            " - 7: -0.0000\n",
            " - 8: -0.0000\n",
            " - 9: -0.0000\n",
            " - 10: -0.0000\n",
            " - 11: -0.0000\n",
            " - 12: -0.0000\n",
            " - 13: -0.0000\n",
            " - 14: -0.0000\n",
            "\n",
            "Attribute: OUTLOOK\n",
            " - SUNNY: 0.9710\n",
            " - OVERCAST: -0.0000\n",
            " - RAIN: 0.9710\n",
            "\n",
            "Attribute: TEMPERTATURE\n",
            " - HOT: 0.9183\n",
            " - HOIT: -0.0000\n",
            " - MILD: 0.9183\n",
            " - COOL: 0.8113\n",
            "\n",
            "Attribute: HUMIDITY\n",
            " - HIGH: 0.9852\n",
            " - NORMAL: 0.5917\n",
            "\n",
            "Attribute: WIND\n",
            " - WEAK: 0.8113\n",
            " - STRONG: 1.0000\n",
            "\n",
            "Information Gain for Each Attribute:\n",
            "DAY: 0.9403\n",
            "OUTLOOK: 0.2467\n",
            "TEMPERTATURE: 0.1182\n",
            "HUMIDITY: 0.1518\n",
            "WIND: 0.0481\n",
            "\n",
            "=== Decision Tree (Row-wise) ===\n",
            "[DAY]\n",
            "  → 1:\n",
            "    ⮕ Decision: NO\n",
            "  → 2:\n",
            "    ⮕ Decision: NO\n",
            "  → 3:\n",
            "    ⮕ Decision: YES\n",
            "  → 4:\n",
            "    ⮕ Decision: YES\n",
            "  → 5:\n",
            "    ⮕ Decision: YES\n",
            "  → 6:\n",
            "    ⮕ Decision: NO\n",
            "  → 7:\n",
            "    ⮕ Decision: YES\n",
            "  → 8:\n",
            "    ⮕ Decision: NO\n",
            "  → 9:\n",
            "    ⮕ Decision: YES\n",
            "  → 10:\n",
            "    ⮕ Decision: YES\n",
            "  → 11:\n",
            "    ⮕ Decision: YES\n",
            "  → 12:\n",
            "    ⮕ Decision: YES\n",
            "  → 13:\n",
            "    ⮕ Decision: YES\n",
            "  → 14:\n",
            "    ⮕ Decision: NO\n"
          ]
        }
      ]
    }
  ]
}